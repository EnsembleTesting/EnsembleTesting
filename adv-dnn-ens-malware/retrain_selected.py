from learner import model_scope_dict
from tools import utils
import numpy as np
'''
Perform retraining with the candidate set selected with test selection metrics.
OOD by adversarial attacks.
'''
import os
import csv
from config import config

tests = [
    {
        'selection_metric': ['gd'],
        'budget': [0.05, 0.1, 0.2, 0.3],
        'id_ratio': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
        'method': ['MIMICRY', 'POINTWISE'],
        'epochs': [30]
    }
]
sample_portion = 0.7
model_name = 'deepdrebin'  # 'deepdrebin', 'basic_dnn'
retrain_type = 'type1'
test_set = 'hybrid'

TYPE1 = 'type1'
TYPE2 = 'type2'
HYBRID = 'hybrid'
ORIGINAL = 'original'
DEEPDREBIN = 'deepdrebin'
BASIC_DNN = 'basic_dnn'
_retrain_epochs = retrain_type == TYPE1 and [30] or [5]

pristine_feat_path = '/drebin/attack_basicDNN/pristine_feature.data'
pristine_feat = utils.readdata_np(pristine_feat_path)
pristine_feat = pristine_feat[:int(pristine_feat.shape[0]*sample_portion)]
trainX, valX, _ = utils.read_joblib('/drebin/X.pkl')
trainy, valy, _ = utils.read_joblib('/drebin/y.pkl')

targeted_model_names_dict = model_scope_dict.copy()
targeted_model_name = model_name
targeted_model = targeted_model_names_dict[targeted_model_name](mode='test')

project_root = config.get('DEFAULT', 'project_root')

def write_to_csv(output_file, data):
    file_exists = os.path.isfile(output_file)
    with open(output_file, 'a') as csvfile:
        fieldnames = ['model', 'retrain_type', 'test_set', 'method', 'selection_metric', 'epochs', 'id_ratio', 'budget',
                      'original_acc', 'retrain_acc', 'acc_improvement', 'learning rate', 'select portion',  'gd_num', 'w_gini', 'w_ent', 'ratio']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        if not file_exists:
            writer.writeheader()
        writer.writerow(data)

def retrain_selected(test_params):
    log_path = os.path.join(project_root, 'results/our_method/',
                            '{}_{}_{}_{}.csv'.format(model_name, retrain_type, test_set, _retrain_epochs))
    selection_metric = test_params['selection_metric']
    bg = test_params['budget']
    retrain_epochs = 'epochs' in test_params and test_params['epochs'] or _retrain_epochs

    id_dist = test_params['id_ratio']
    methods = test_params['method']
    if targeted_model_name == 'deepdrebin':
        perturbed_paths = {'fgsm': '/drebin/attack_deepdrebin/adversarial_samples/fgsm/fgsm_l-infinity.data',
                    'GDKDE': '/drebin/attack_deepdrebin/adversarial_samples/gdkde/gdkde_.data',
                       'MIMICRY': '/drebin/attack_deepdrebin/adversarial_samples/mimicry/mimicry_.data',
                      'POINTWISE': '/drebin/attack_deepdrebin/adversarial_samples/pointwise/pointwise_.data'}

    elif targeted_model_name == 'basic_dnn':
        perturbed_paths = {'fgsm': '/drebin/attack_basicDNN/adversarial_samples/fgsm/fgsm_l-infinity.data',
                           'GDKDE': '/drebin/attack_basicDNN/adversarial_samples/gdkde/gdkde_.data',
                           'MIMICRY': '/drebin/attack_basicDNN/adversarial_samples/mimicry/mimicry_.data',
                           'POINTWISE': '/drebin/attack_basicDNN/adversarial_samples/pointwise/pointwise_.data'}


    for method in methods:
        perturbed_path = perturbed_paths[method]
        perturbed_feat = utils.readdata_np(perturbed_path)
        perturbed_feat = perturbed_feat[:int(perturbed_feat.shape[0] * sample_portion)]
        for epochs in retrain_epochs:
            for metric in selection_metric:
                for budget in bg:
                    accuracies, ori_accs = [], []
                    for id_ratio in id_dist:
                        id_size = int(pristine_feat.shape[0]*id_ratio)
                        ood_size = int(pristine_feat.shape[0] - id_size)
                        id_feat = pristine_feat[:id_size]

                        # split id feat into two sets
                        candidate_set_id = id_feat[:int(id_size*0.5)]
                        test_set_id = id_feat[int(id_size*0.5):]

                        ood_feat = perturbed_feat[id_size:]
                        candidate_set_ood = ood_feat[:int(ood_size*0.5)]
                        test_set_ood = ood_feat[int(ood_size*0.5):]

                        # reconstruct hybrid test set and hybrid candidate set
                        hybrid_candidate_set = np.concatenate((candidate_set_id, candidate_set_ood), axis=0)
                        hybrid_test_set = np.concatenate((test_set_id, test_set_ood), axis=0)
                        labels = np.ones(hybrid_test_set.shape[0])
                        test_labels = np.ones(hybrid_test_set.shape[0])

                        _testX, _testy = None, None

                        if test_set == HYBRID:
                            _testX, _testy = hybrid_test_set, labels
                        else:
                            _testX, _testy = testX, testy

                        ori_acc = targeted_model.test_rpst(testX=_testX, testy=_testy, is_single_class=True)

                        if budget == 1.0:
                            if retrain_type == TYPE1:
                                retrainX, retrainy = hybrid_candidate_set, labels
                            else:
                                retrainX = np.concatenate((hybrid_candidate_set, trainX), axis=0)
                                retrainy = np.concatenate((labels, trainy), axis=0)
                        else:
                            selected_candidateX, selected_candidatey = targeted_model.selection(
                                budget=budget,
                                trainX=trainX,
                                trainy=trainy,
                                candidateX=hybrid_candidate_set,
                                candidateX_id=candidate_set_id,
                                candidatey=labels,
                                candidatey_id=np.ones(candidate_set_id.shape[0]),
                                hybrid_test=hybrid_test_set,
                                hybrid_testy=test_labels,
                                metric=metric,
                                id_ratio=id_ratio)
                            if retrain_type == TYPE1:
                                retrainX, retrainy = selected_candidateX, selected_candidatey
                            else:
                                concated_trainX = np.concatenate((selected_candidateX, trainX), axis=0)
                                concated_trainy = np.concatenate((selected_candidatey, trainy), axis=0)
                                retrainX, retrainy = concated_trainX, concated_trainy

                        acc = targeted_model.retrain(candidateX=retrainX, candidatey=retrainy, testX=_testX, testy=_testy, epochs=epochs)
                        lr = targeted_model.lr
                        accuracies.append(acc*100)
                        ori_accs.append(ori_acc*100)
                    for i in range(len(id_dist)):
                        write_to_csv(log_path, {'method': method, 'id_ratio': id_dist[i], 'budget': budget,
                                                'selection_metric': metric, 'original_acc': ori_accs[i],
                                                'retrain_acc': accuracies[i],
                                                'acc_improvement': accuracies[i] - ori_accs[i], 'epochs': epochs,
                                                'retrain_type': retrain_type, 'test_set': test_set, 'model': model_name,
                                                'learning rate': lr,
                                                'select portion': sample_portion})

our_method_params = {}
our_method_params['gd_num'], our_method_params['w_gini'], our_method_params['w_ent'], our_method_params['ratio'] = 60, 0.5, 0.5, 0.8

test_suite_params = [
    {
        'method': ['fgsm'],#['fgsm', 'GDKDE', 'MIMICRY', 'POINTWISE'],
        'selection_metric': ['random'],#['random', 'gd', 'entropy', 'deepgini', 'dat', 'dat_ood_detector'],
        'budget': [0.05],#[0.05, 0.1, 0.2, 0.3],
        'id_ratio': [0.0]#[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
    }
]
test_suite_dir = '/adv-dnn-ens-malware/Drebin_test_suite/'

def save_test_suite(p):
    for method in p['method']:
        perturbed_path = all_perturbed_paths[all_methods.index(method)]
        if perturbed_path is None:
            continue
        perturbed_feat = utils.readdata_np(perturbed_path)
        for selection_metric in p['selection_metric']:
            for budget in p['budget']:
                for id_ratio in p['id_ratio']:
                    if selection_metric == 'dat' and id_ratio == 1.0:
                        continue

                    path = os.path.join(test_suite_dir, model_name, method, selection_metric, str(budget),
                                        str(id_ratio))
                    #if os.path.exists(path):
                    #    continue

                    id_size = int(pristine_feat.shape[0] * id_ratio)
                    ood_size = int(pristine_feat.shape[0] - id_size)
                    id_feat = pristine_feat[:id_size]

                    candidate_set_id = id_feat[:int(id_size * 0.5)]
                    test_set_id = id_feat[int(id_size * 0.5):]

                    ood_feat = perturbed_feat[id_size:]
                    candidate_set_ood = ood_feat[:int(ood_size * 0.5)]
                    test_set_ood = ood_feat[int(ood_size * 0.5):]

                    hybrid_candidate_set = np.concatenate((candidate_set_id, candidate_set_ood), axis=0)
                    hybrid_test_set = np.concatenate((test_set_id, test_set_ood), axis=0)
                    labels = np.ones(hybrid_test_set.shape[0])
                    test_labels = np.ones(hybrid_test_set.shape[0])

                    selected_candidateX, selected_candidatey = targeted_model.selection(
                        budget=budget,
                        trainX=trainX,
                        trainy=trainy,
                        candidateX=hybrid_candidate_set,
                        candidateX_id=candidate_set_id,
                        candidatey=labels,
                        candidatey_id=np.ones(candidate_set_id.shape[0]),
                        hybrid_test=hybrid_test_set,
                        hybrid_testy=test_labels,
                        metric=selection_metric,
                        id_ratio=id_ratio)

                    utils.dumpdata_np(selected_candidateX, os.path.join(path, 'X.data'))
                    utils.dumpdata_np(selected_candidatey, os.path.join(path, 'y.data'))

                    feat = utils.readdata_np(os.path.join(path, 'X.data'))
                    y_gt = utils.readdata_np(os.path.join(path, 'y.data'))
                    y_pred, X_feat = targeted_model.test_pred_feat(testX=feat, testy=y_gt)
                    utils.dumpdata_np(X_feat, os.path.join(path, 'X_feat.data'))
                    utils.dumpdata_np(y_pred, os.path.join(path, 'y_pred.data'))

ori_tests = [
    {
        'id_ratio': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
        'method': ['fgsm', 'GDKDE', 'MIMICRY', 'POINTWISE'],
    }
]

def main():
    for test in tests:
        retrain_selected(test)
    #for p in test_suite_params:
    #    save_test_suite(p)

if __name__ == '__main__':
    main()