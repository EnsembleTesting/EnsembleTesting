from learner import model_scope_dict
from tools import utils
import numpy as np
import os

# load AndroZoo data (OOD)
androX_path = '/androzoo/derbin/X.pkl'
androy_path = '/androzoo/derbin/y.pkl'
_, _, testX_andro = utils.read_joblib(androX_path)
_, _, testy_andro = utils.read_joblib(androy_path)

# load Drebin data (ID)
drebinX_path = '/drebin/X.pkl'
drebiny_path = '/drebin/y.pkl'
trainX_drebin, _, testX_drebin = utils.read_joblib(drebinX_path)
trainy_drebin, _, testy_drebin = utils.read_joblib(drebiny_path)

# split test data into candidate & new test
size = 4000
candidate_andro_idx = np.random.choice(np.arange(len(testX_andro)), size=size, replace=False)
candidate_drebin_idx = np.random.choice(np.arange(len(testX_drebin)), size=size, replace=False)

can_andro, can_androy = testX_andro[candidate_andro_idx], testy_andro[candidate_andro_idx]
can_drebin, can_drebiny = testX_drebin[candidate_drebin_idx], testy_drebin[candidate_drebin_idx]

test_andro, test_androy = np.delete(testX_andro, candidate_andro_idx, axis=0)[:size], np.delete(testy_andro, candidate_andro_idx)[:size]
test_drebin, test_drebiny = np.delete(testX_drebin, candidate_drebin_idx, axis=0)[:size], np.delete(testy_drebin, candidate_drebin_idx)[:size]

import csv
def write_to_csv(output_files, data):
    for output_file in output_files:
        with open(output_file, 'a') as f:
            writer = csv.DictWriter(f, fieldnames=FIELDS)
            if os.stat(output_file).st_size == 0:
                writer.writeheader()
            for row in data:
                writer.writerow(row)



tests = [
    {
        'retrain_type': 'type1',
        'selection_metric': ['gd'],
        'budget': [0.1, 0.05, 0.03, 0.01],
        'id_ratio': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
        'method': ['out-of-src']
    }
]
TYPE2_TEST_LIMIT = 5000

targeted_model_names_dict = model_scope_dict.copy()
model_name = 'basic_dnn' #'deepdrebin', basic_dnn
targeted_model = targeted_model_names_dict[model_name](mode='test')
test_set = 'hybrid'
dataset = 'Drebin'

TYPE1 = 'type1'
TYPE2 = 'type2'
HYBRID = 'hybrid'
ORIGINAL = 'original'
INF = 1e9
FIELDS = ['model', 'dataset', 'retrain_type', 'test_set', 'method', 'selection_metric', 'epochs', 'id_ratio', 'budget', 'original_acc', 'retrain_acc', 'acc_improvement', 'learning rate', 'gd_num', 'w_gini', 'w_ent', 'ratio']

our_method_params = {}
our_method_params['gd_num'], our_method_params['w_gini'], our_method_params['w_ent'], our_method_params['ratio'] = 60, 0.5, 0.5, 1.0

test_suite_dir = '/adv-dnn-ens-malware/Drebin_test_suite/'
def retrain_outofsrc(params, save=False):
    selection_metric = params['selection_metric']
    bg = params['budget']
    epochs = params['retrain_type'] == TYPE1 and 30 or 5
    id_dist = params['id_ratio']
    methods = params['method']
    log_path = [
        os.path.join('/adv-dnn-ens-malware/results/our_method',
                     '{}_{}_{}_{}_{}_{}_{}.csv'.format(model_name, params['retrain_type'], test_set, epochs,
                                                       our_method_params['w_gini'], our_method_params['w_ent'],
                                                       our_method_params['ratio']))
    ]
    for method in methods:
        for metric in selection_metric:
            for budget in bg:
                accuracies, ori_accs = [], []
                for id_ratio in id_dist:
                    id_size = int(can_drebin.shape[0] * id_ratio)
                    id_feat_can, id_y_can = can_drebin[:id_size], can_drebiny[:id_size]
                    id_feat_test, id_y_test = test_drebin[:id_size], test_drebiny[
                                                                    :id_size]

                    ood_size = size - id_size
                    ood_feat_can, ood_y_can = can_andro[:ood_size], can_androy[:ood_size]
                    ood_feat_test, ood_y_test = test_andro[:ood_size], test_androy[:ood_size]

                    hybrid_candidateX = np.concatenate((id_feat_can, ood_feat_can), axis=0)
                    hybrid_candidatey = np.concatenate((id_y_can, ood_y_can), axis=0)

                    hybrid_testX = np.concatenate((id_feat_test, ood_feat_test), axis=0)
                    hybrid_testy = np.concatenate((id_y_test, ood_y_test), axis=0)

                    ori_acc = targeted_model.test_rpst(testX=hybrid_testX, testy=hybrid_testy, is_single_class=True)
                    if budget == 1.0:
                        if params['retrain_type'] == TYPE1:
                            retrainX, retrainy = hybrid_candidateX, hybrid_candidatey
                        else:
                            trun = min(len(trainX_drebin), TYPE2_TEST_LIMIT)
                            retrainX = np.concatenate((hybrid_candidateX, trainX_drebin[:trun]), axis=0)
                            retrainy = np.concatenate((hybrid_candidatey, trainy_drebin[:trun]), axis=0)
                    else:
                        selected_candidateX, selected_candidatey = targeted_model.selection(budget=budget, trainX=trainX_drebin,
                                                                                        trainy=trainy_drebin,
                                                                                        candidateX=hybrid_candidateX,
                                                                                        candidateX_id=id_feat_can,
                                                                                        candidatey=hybrid_candidatey,
                                                                                        candidatey_id=id_y_can,
                                                                                        hybrid_test=hybrid_testX,
                                                                                        hybrid_testy=hybrid_testy, metric=metric,
                                                                                        id_ratio=id_ratio, our_method_params=our_method_params)
                        if save==True:
                            path = os.path.join(test_suite_dir, model_name, method, metric,
                                                str(our_method_params['w_gini']) + '_' + str(
                                                    our_method_params['w_ent']) + '_' + str(our_method_params['ratio']),
                                                str(budget), str(id_ratio))
                            utils.dumpdata_np(selected_candidateX, os.path.join(path, 'X.data'))
                            utils.dumpdata_np(selected_candidatey, os.path.join(path, 'y.data'))

                            y_pred, X_feat = targeted_model.test_pred_feat(testX=selected_candidateX,
                                                                           testy=selected_candidatey)  # X_feat=(20,160)
                            utils.dumpdata_np(X_feat, os.path.join(path, 'X_feat.data'))
                            utils.dumpdata_np(y_pred, os.path.join(path, 'y_pred.data'))

                        if params['retrain_type'] == TYPE1:
                            retrainX, retrainy = selected_candidateX, selected_candidatey
                        else:
                            trun = min(len(trainX_drebin), TYPE2_TEST_LIMIT)
                            concated_trainX = np.concatenate((selected_candidateX, trainX_drebin[:trun]), axis=0)
                            concated_trainy = np.concatenate((selected_candidatey, trainy_drebin[:trun]), axis=0)
                            retrainX, retrainy = concated_trainX, concated_trainy
                    retrain_acc = targeted_model.retrain(candidateX=retrainX, candidatey=retrainy, testX=hybrid_testX, testy=hybrid_testy, epochs=epochs)
                    lr = targeted_model.lr
                    accuracies.append(retrain_acc*100)
                    ori_accs.append(ori_acc*100)

                    write_to_csv(log_path, [
                        {
                            'model': model_name,
                            'dataset': dataset,
                            'retrain_type': params['retrain_type'],
                            'test_set': test_set,
                            'method': method,
                            'selection_metric': metric,
                            'epochs': epochs,
                            'id_ratio': id_ratio,
                            'budget': budget,
                            'original_acc': ori_acc * 100,
                            'retrain_acc': retrain_acc * 100,
                            'acc_improvement': (retrain_acc - ori_acc) * 100,
                            'learning rate': lr,
                            'gd_num': our_method_params['gd_num'],
                            'w_gini': our_method_params['w_gini'],
                            'w_ent': our_method_params['w_ent'],
                            'ratio': our_method_params['ratio']
                        }
                    ])

def main():
    for test in tests:
        retrain_outofsrc(test, True)

if __name__ == '__main__':
    main()